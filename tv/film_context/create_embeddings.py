# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Create embeddings from comprehensive film context documents

Takes the rich film documents generated by data_gatherer.py and converts them
into embeddings suitable for semantic search and AI commentary.
"""

import json
import sys
from pathlib import Path

from google import genai
from google.genai import types


def chunk_text(text, chunk_size=1000, overlap=200):
    """Split text into overlapping chunks"""
    chunks = []
    start = 0
    while start < len(text):
        end = start + chunk_size
        chunk = text[start:end]
        chunks.append(chunk)
        start = end - overlap
    return chunks


async def create_film_embeddings(context_file: str, output_file: str = None):
    """Create embeddings from film context document

    Args:
        context_file: Path to the film context document
        output_file: Optional output file path (auto-generated if not provided)
    """

    # Validate input file
    context_path = Path(context_file)
    if not context_path.exists():
        raise FileNotFoundError(f"Context file not found: {context_file}")

    # Generate output filename if not provided
    if not output_file:
        output_file = context_path.stem + "_embeddings.json"

    print(f"üé¨ Creating embeddings from: {context_file}")
    print(f"üìÑ Output file: {output_file}")
    print("=" * 60)

    # Initialize Gemini client
    client = genai.Client()

    # Read film context document
    print("üìñ Reading film context document...")
    with open(context_file, "r", encoding="utf-8") as f:
        text = f.read()

    print(f"‚úÖ Loaded document: {len(text):,} characters")

    # Split into chunks
    print("‚úÇÔ∏è Chunking document...")
    chunks = chunk_text(text)
    print(f"‚úÖ Created {len(chunks)} chunks")

    # Create embeddings
    print("\nüîÆ Creating embeddings...")
    embeddings_data = []

    for i, chunk in enumerate(chunks):
        print(f"Processing chunk {i+1}/{len(chunks)}")

        try:
            response = client.models.embed_content(
                model="gemini-embedding-001",
                contents=chunk,
                config=types.EmbedContentConfig(task_type="retrieval_document"),
            )

            embeddings_data.append({"chunk_id": i, "text": chunk, "embedding": response.embeddings[0].values})

        except Exception as e:
            print(f"‚ùå Error processing chunk {i+1}: {e}")
            # Continue with other chunks
            continue

    # Save embeddings to file
    print(f"\nüíæ Saving embeddings...")
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(embeddings_data, f)

    print(f"‚úÖ Embeddings saved to: {output_file}")
    print(f"üìä Final stats:")
    print(f"   Total chunks: {len(chunks)}")
    print(f"   Successful embeddings: {len(embeddings_data)}")
    print(f"   Document coverage: {len(embeddings_data)/len(chunks)*100:.1f}%")

    return output_file


if __name__ == "__main__":
    import asyncio

    async def main():
        if len(sys.argv) < 2:
            print("Usage: python create_embeddings.py 'context_file.txt' [output_file.json]")
            print("Example: python create_embeddings.py 'The_Big_Sleep_1946_context.txt'")
            sys.exit(1)

        context_file = sys.argv[1]
        output_file = sys.argv[2] if len(sys.argv) > 2 else None

        try:
            result_file = await create_film_embeddings(context_file, output_file)
            print(f"\nüéâ Success! Film embeddings created.")
            print(f"üìÑ Ready for semantic search: {result_file}")

        except Exception as e:
            print(f"‚ùå Error: {e}")
            import traceback

            traceback.print_exc()
            sys.exit(1)

    asyncio.run(main())
